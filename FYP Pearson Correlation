import numpy as np
import pandas as pd

y = np.array([169, 164, 172, 145, 170, 153, 147, 149, 173, 153, 152, 150.5, 149, 158, 159, 167, 154, 176, 149, 151, 148, 160, 153, 166, 157, 155, 153, 125, 149, 162, 170.18, 165, 161.2, 155, 154, 168, 153, 183, 173, 176, 175, 169, 168, 155, 156, 155, 151, 165, 156, 156, 142])
x = np.array([28, 20.5, 24, 22.5, 22.5, 24, 21.5, 22.9, 27.5, 23.5, 22.6, 23.3, 22, 24, 24.5, 26, 23.5, 24, 21.5, 23, 21.5, 24.7, 23.6, 24.5, 22.5, 22, 23.7, 18, 23.5, 23, 28.5, 25, 25.5, 22.8, 23, 25.8, 38, 27.8, 25, 26, 24.5, 25.5, 23.5, 23.5, 25.5, 36, 23.9, 25, 23.5, 24.6, 22])

# defining the function to fit the data to
def f(x, a, b):
    return a*x + b

# solving for the coefficients a and b
a, b = np.linalg.lstsq(np.vstack([x, np.ones(len(x))]).T, y, rcond=None)[0]

# computing the estimated heights and errors
estimated_heights = f(x, a, b)
errors = y - estimated_heights

# creating a pandas DataFrame with the results
results_df = pd.DataFrame({'Foot Length': x, 'Actual Height': y, 'Estimated Height': estimated_heights, 'Error': errors})

print(results_df)
import numpy as np
import pandas as pd

y = np.array([169, 164, 172, 145, 170, 153, 147, 149, 173, 153, 152, 150.5, 149, 158, 159, 167, 154, 176, 149, 151, 148, 160, 153, 166, 157, 155, 153, 125, 149, 162, 170.18, 165, 161.2, 155, 154, 168, 153, 183, 173, 176, 175, 169, 168, 155, 156, 155, 151, 165, 156, 156, 142])
x = np.array([28, 20.5, 24, 22.5, 22.5, 24, 21.5, 22.9, 27.5, 23.5, 22.6, 23.3, 22, 24, 24.5, 26, 23.5, 24, 21.5, 23, 21.5, 24.7, 23.6, 24.5, 22.5, 22, 23.7, 18, 23.5, 23, 28.5, 25, 25.5, 22.8, 23, 25.8, 38, 27.8, 25, 26, 24.5, 25.5, 23.5, 23.5, 25.5, 36, 23.9, 25, 23.5, 24.6, 22])

# defining the function to fit the data to
def f(x, a, b):
    return a*x + b

# solving for the coefficients a and b
a, b = np.linalg.lstsq(np.vstack([x, np.ones(len(x))]).T, y, rcond=None)[0]

# computing the estimated heights and errors
estimated_heights = f(x, a, b)
errors = y - estimated_heights

# creating a pandas DataFrame with the results
results_df = pd.DataFrame({'Foot Length': x, 'Actual Height': y, 'Estimated Height': estimated_heights, 'Error': errors})

print(results_df)

# solving for the coefficients a and b
a, b = np.linalg.lstsq(np.vstack([x, np.ones(len(x))]).T, y, rcond=None)[0]

# creating the equation string
equation_string = f'Height = {a:.4f} * Foot Length + {b:.4f}'

# plotting the data and the linear fit
fig, ax = plt.subplots(figsize=(10,6))  # Adjust the figure size as needed
ax.plot(x, y, 'bo', label='data')
ax.plot(x, f(x, a, b), 'r-', label='linear fit')
ax.legend()
ax.set_xlabel('Foot Length')
ax.set_ylabel('Height')
ax.text(0, 0.95, equation_string, transform=ax.transAxes, fontsize=12,
        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.5))
plt.show()

# solving for the coefficients a and b
a, b = np.linalg.lstsq(np.vstack([x, np.ones(len(x))]).T, y, rcond=None)[0]

# calculating the predicted y values
y_pred = a * x + b

# calculating the total sum of squares (TSS)
TSS = np.sum((y - np.mean(y))**2)

# calculating the residual sum of squares (RSS)
RSS = np.sum((y - y_pred)**2)

# calculating the R-squared value
R_squared = 1 - (RSS / TSS)

# calculating the adjusted R-squared value
n = len(x)  # number of data points
p = 2  # number of predictors (a and b)
adjusted_R_squared = 1 - ((1 - R_squared) * (n - 1) / (n - p - 1))

# calculating the mean squared error (MSE)
mse = np.mean((y - y_pred)**2)

# calculating the root mean squared error (RMSE)
rmse = np.sqrt(mse)

# calculating the Bayesian information criterion (BIC)
bic = n * np.log(mse) + p * np.log(n)

# calculating the Akaike information criterion (AIC)
aic = n * np.log(mse) + 2 * p

print("R-squared:", R_squared)
print("Adjusted R-squared:", adjusted_R_squared)
print("MSE:", mse)
print("RMSE:", rmse)
print("BIC:", bic)
print("AIC:", aic)

